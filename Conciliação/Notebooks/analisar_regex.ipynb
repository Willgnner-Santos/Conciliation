{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d073ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# ================================\n",
    "# CONFIGURAÇÃO\n",
    "# ================================\n",
    "CAMINHO_ARQUIVO_JSON = r\"C:\\Users\\Documents\\Modelos\\Perfil-Conciliação-Xgboost-GCP-V2\\dados\\anonymous_14052025\\dados_processos_anonymous_14052025_V1_enriquecidos.json\"\n",
    "CAMINHO_RELATORIO_SAIDA = Path(CAMINHO_ARQUIVO_JSON).with_name(\"frequencia_tokens_artificiais.txt\")\n",
    "\n",
    "TOKENS_PADROES = [\n",
    "    \"NOME_PESSOA\",\n",
    "    \"NOME_PESSOA_REP\",\n",
    "    \"NUM\",\n",
    "    \"NUM_REP\",\n",
    "    \"VALOR_MONETARIO\",\n",
    "    \"VALOR_MONETARIO_REP\",\n",
    "    \"CIDADE_UF\",\n",
    "    \"ENDERECO\",\n",
    "    \"CEP\",\n",
    "    \"CPF\",\n",
    "    \"CNPJ\"\n",
    "]\n",
    "\n",
    "# ================================\n",
    "# FUNÇÕES\n",
    "# ================================\n",
    "\n",
    "def contar_tokens(texto: str, tokens_padroes):\n",
    "    counter = Counter()\n",
    "    for token in tokens_padroes:\n",
    "        padrao = rf\"\\b{re.escape(token)}\\b\"\n",
    "        ocorrencias = len(re.findall(padrao, texto))\n",
    "        counter[token] += ocorrencias\n",
    "    return counter\n",
    "\n",
    "# ================================\n",
    "# EXECUÇÃO\n",
    "# ================================\n",
    "\n",
    "def analisar_tokens_em_json(caminho_json, tokens_padroes):\n",
    "    with open(caminho_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        dados = json.load(f)\n",
    "\n",
    "    contagem_total = Counter()\n",
    "    n_docs = 0\n",
    "\n",
    "    for item in dados:\n",
    "        texto = item.get(\"inteiro_teor_limpo\", \"\")\n",
    "        if not texto:\n",
    "            continue\n",
    "        n_docs += 1\n",
    "        contagem = contar_tokens(texto, tokens_padroes)\n",
    "        contagem_total.update(contagem)\n",
    "\n",
    "    # Relatório final\n",
    "    relatorio = [f\"Total de documentos analisados: {n_docs}\\n\"]\n",
    "    for token in tokens_padroes:\n",
    "        total = contagem_total[token]\n",
    "        media = total / n_docs if n_docs else 0\n",
    "        relatorio.append(f\"{token:<25} → total: {total:>6} | média por doc: {media:.2f}\")\n",
    "\n",
    "    # Salva em arquivo\n",
    "    with open(CAMINHO_RELATORIO_SAIDA, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(relatorio))\n",
    "\n",
    "    # Também imprime no terminal\n",
    "    print(\"\\n\".join(relatorio))\n",
    "    print(f\"\\nRelatório salvo em: {CAMINHO_RELATORIO_SAIDA}\")\n",
    "\n",
    "# ================================\n",
    "# EXECUTAR\n",
    "# ================================\n",
    "if __name__ == \"__main__\":\n",
    "    analisar_tokens_em_json(CAMINHO_ARQUIVO_JSON, TOKENS_PADROES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
